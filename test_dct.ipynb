{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2 \n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from torch.nn import NLLLoss, LogSoftmax\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from lvc import create_dct\n",
    "from test_nn import get_imagenet_labels, WEIGHTS, Dct, Idct\n",
    "from probe import probe\n",
    "from utils import set_device\n",
    "\n",
    "device = set_device()\n",
    "norm = \"ortho\"\n",
    "show_dct = False\n",
    "show_gradients = True\n",
    "do_dct_test = False\n",
    "img_size = (3, 256, 256)  # size of resized images\n",
    "inp_size = (3, 224, 224)  # size of cropped images fed into NN\n",
    "N = 1\n",
    "dct_size = 16\n",
    "\n",
    "# Setup data\n",
    "inp_dir = '/home/kubouch/data/imagenet_subsets/subset_10class_1000perclass/val'\n",
    "# inp_dir = '/home/jakub/pictures/kodim/raw'\n",
    "glob = '*/*.jpg'\n",
    "# glob = '*23.png'\n",
    "pics = [str(img) for img in Path(inp_dir).glob(glob)][:N]\n",
    "labels = get_imagenet_labels(pics)  # np.zeros(len(pics))\n",
    "batch_size = min(len(pics), 32)\n",
    "w_human = torch.Tensor([0.299, 0.587, 0.114])\n",
    "\n",
    "# Try block-based DCT\n",
    "show_gradients = False\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(img_size[1]),\n",
    "        transforms.CenterCrop(inp_size[1]),\n",
    "        transforms.ToTensor(),\n",
    "        # RgbToYcbcr(W),\n",
    "        #  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "img = preprocess(Image.open(pics[0]).convert(\"RGB\"))\n",
    "\n",
    "# dct_enc, dct_dec = create_dct(\n",
    "#     (dct_size, dct_size),\n",
    "#     dct_size * dct_size,\n",
    "#     w_human,\n",
    "#     device,\n",
    "#     False,\n",
    "#     do_print=False,\n",
    "# )\n",
    "\n",
    "model_name = \"alexnet\"\n",
    "model = torch.hub.load(\n",
    "    \"pytorch/vision:v0.13.1\", model_name, weights=WEIGHTS[model_name]\n",
    ")\n",
    "activ = LogSoftmax(dim=1)\n",
    "loss_func = NLLLoss()\n",
    "\n",
    "grads = probe(\n",
    "    model,\n",
    "    pics,\n",
    "    labels,\n",
    "    preprocess,\n",
    "    Dct(),\n",
    "    Idct(),\n",
    "    activ,\n",
    "    loss_func,    \n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"Img size: \", img.shape)\n",
    "dct = Dct()(img)\n",
    "dct_blocks = dct[0][0]\n",
    "dct_y, dct_u, dct_v = dct_blocks.chunk(3)\n",
    "print(\"DCT shape: \", dct_blocks.shape)\n",
    "print(\"DCT Y shape: \", dct_y.shape)\n",
    "print(\"DCT U shape: \", dct_u.shape)\n",
    "print(\"DCT V shape: \", dct_v.shape)\n",
    "idct = Idct()(dct)\n",
    "print(\"IDCT shape: \", idct.shape)\n",
    "print((idct - img).mean().square())\n",
    "\n",
    "idct_img = transforms.ToPILImage()(idct)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(idct_img)\n",
    "plt.figure()\n",
    "plt.imshow(transforms.ToPILImage()(img))\n",
    "plt.figure()\n",
    "plt.imshow(transforms.ToPILImage()(grads[0]))\n",
    "\n",
    "# cmap = cm.jet\n",
    "# gmin = g_yuv_mean_blocks.min()\n",
    "# gmax = g_yuv_mean_blocks.max()\n",
    "\n",
    "# dct_y_mean = dct_y.mean(dim=0)\n",
    "# dct_u_mean = dct_u.mean(dim=0)\n",
    "# dct_v_mean = dct_v.mean(dim=0)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.subplot(311)\n",
    "# plt.imshow(dct_y_mean, cmap=cmap)#, norm=plt.Normalize(gmin, gmax))\n",
    "# plt.colorbar(fraction=0.045)\n",
    "# plt.title(\"sensitivity map -- mean DCT gradient (Y)\")\n",
    "\n",
    "# plt.subplot(312)\n",
    "# plt.imshow(dct_u_mean, cmap=cmap)#, norm=plt.Normalize(gmin, gmax))\n",
    "# plt.colorbar(fraction=0.045)\n",
    "# plt.title(\"sensitivity map -- mean DCT gradient (U)\")\n",
    "\n",
    "# plt.subplot(313)\n",
    "# plt.imshow(dct_v_mean, cmap=cmap)#, norm=plt.Normalize(gmin, gmax))\n",
    "# plt.colorbar(fraction=0.045)\n",
    "# plt.title(\"sensitivity map -- mean DCT gradient (V)\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.rand(5)\n",
    "t.requires_grad_(True)\n",
    "t.retain_grad()\n",
    "print(t)\n",
    "\n",
    "ttop, ttop_idx = t.topk(3)\n",
    "ttop.requires_grad_(True)\n",
    "ttop.retain_grad()\n",
    "print(ttop)\n",
    "\n",
    "y = ttop.sum()\n",
    "print(y)\n",
    "\n",
    "y.backward()\n",
    "print(ttop.grad)\n",
    "print(t.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2056f0fd95020c38eba01d39f4b8309efee9756a0a7bda45759d0dc0375c69c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
