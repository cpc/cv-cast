{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single run of LVC + NN model used for testing\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reset -f\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "gpu_i = 7\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_i}\"\n",
    "os.environ[\"DRJIT_LIBLLVM_PATH\"] = \"/usr/lib/llvm-14/lib/libLLVM.so\"\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "# import tensorflow as tf\n",
    "\n",
    "from lvc.lvc import create_lvc, GradConfig, JPEGConfig, SionnaConfig\n",
    "from models import get_model, get_model_id\n",
    "from models.model import plot_channels\n",
    "from utils import set_device\n",
    "from utils.q_search import fetch_param\n",
    "\n",
    "device = set_device(f\"cuda:0\")\n",
    "cpus = set(range(gpu_i * 96 // 8, gpu_i * 96 // 8 + 96 // 8))\n",
    "os.sched_setaffinity(0, cpus)\n",
    "affinity = os.sched_getaffinity(0)\n",
    "print(f\"Running on CPUs: {affinity}\")\n",
    "torch.set_num_threads(len(cpus))\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "\n",
    "Q_SEARCH_FILES = {\n",
    "    \"fastseg_small\": \"experiments_tupu/runs/run21_keep/q_search_fastseg_small_Noneimgs.pt\",\n",
    "    \"fastseg_large\": \"experiments_tupu/runs/run22_keep/q_search_fastseg_large_Noneimgs.pt\",\n",
    "    \"yolov8_n\": \"experiments_hupu/runs/run49_keep/q_search_yolov8_n_Noneimgs.pt\",\n",
    "    \"yolov8_s\": \"experiments_hupu/runs/run50_keep/q_search_yolov8_s_Noneimgs.pt\",\n",
    "    \"yolov8_l\": \"experiments_hupu/runs/run51_keep/q_search_yolov8_l_Noneimgs.pt\",\n",
    "}\n",
    "\n",
    "yolov8_name = \"yolov8\"\n",
    "yolov8_variant = \"n\"\n",
    "config_yolov8 = {\n",
    "    \"name\": yolov8_name,\n",
    "    \"variant\": yolov8_variant,\n",
    "    \"task\": \"detect\",\n",
    "    \"snapshot\": f\"{yolov8_name}{yolov8_variant}.pt\",\n",
    "    \"unit\": \"mAP_50_95\",\n",
    "    \"data_file\": \"coco.yaml\",\n",
    "}\n",
    "\n",
    "config_fastseg = {\n",
    "    \"name\": \"fastseg\",\n",
    "    \"variant\": \"small\",\n",
    "    # \"variant\": \"large\",\n",
    "    \"snapshot\": (\n",
    "        Path.home() / \"data/models/fastseg/raw/small/best_checkpoint_ep171.pth\"\n",
    "        # Path.home() / \"data/models/fastseg/raw/large/best_checkpoint_ep172.pth\"\n",
    "    ),\n",
    "    \"unit\": \"mean_iu\",\n",
    "}\n",
    "\n",
    "config = config_fastseg\n",
    "\n",
    "model_id = get_model_id(config)\n",
    "print(f\"Model: {model_id}\")\n",
    "\n",
    "color_space = \"yuv\"\n",
    "yuv_mode = 444\n",
    "nchunks = 64\n",
    "cr = 0.25\n",
    "csnr_dbs = [15]\n",
    "estimator = \"zf\"\n",
    "do_print = True\n",
    "\n",
    "codec = \"jpeg\"\n",
    "# sionna_config: SionnaConfig = { \"nbits_per_sym\": 2, \"coderate\": 1.0 }\n",
    "sionna_config: SionnaConfig = { \"nbits_per_sym\": 2, \"coderate\": 0.5 }\n",
    "\n",
    "if codec is not None:\n",
    "    param = fetch_param(\n",
    "        pd.DataFrame(torch.load(Q_SEARCH_FILES[model_id])),\n",
    "        model_id,\n",
    "        codec,\n",
    "        sionna_config[\"nbits_per_sym\"],\n",
    "        cr,\n",
    "    )\n",
    "else:\n",
    "    param = None\n",
    "\n",
    "print(f\"Codec: {codec}, param: {param}\")\n",
    "\n",
    "if codec == \"grace\":\n",
    "    jpeg_config: JPEGConfig = {\n",
    "        \"codec\": \"grace\",\n",
    "        \"param\": param,\n",
    "        \"param_name\": \"B\",\n",
    "        \"param_fmt\": \"{:12.5e}\",\n",
    "        \"turbojpeg_enc\": False,\n",
    "        \"turbojpeg_dec\": False,\n",
    "    }\n",
    "elif codec == \"jpeg\":\n",
    "    jpeg_config: JPEGConfig = {\n",
    "        \"codec\": \"jpeg\",\n",
    "        \"param\": param,\n",
    "        \"param_name\": \"Q\",\n",
    "        \"param_fmt\": \"{:3}\",\n",
    "        \"turbojpeg_enc\": False,\n",
    "        \"turbojpeg_dec\": False,\n",
    "    }\n",
    "else:\n",
    "    jpeg_config = None\n",
    "\n",
    "for csnr_db in csnr_dbs:\n",
    "    print(f\"--- CSNR: {csnr_db} dB\")\n",
    "\n",
    "    lvc_params = {\n",
    "        \"packet_loss\": None,\n",
    "        \"seed\": SEED,\n",
    "        \"mode\": yuv_mode,\n",
    "        \"cr\": cr,\n",
    "        \"csnr_db\": csnr_db,\n",
    "        \"estimator\": estimator,\n",
    "        \"nchunks\": nchunks,\n",
    "        \"color_space\": color_space,\n",
    "        # block-based DCT settings\n",
    "        # \"dct_w\": int(math.sqrt(nchunks)),\n",
    "        # \"dct_h\": int(math.sqrt(nchunks)),\n",
    "        # \"grouping\": \"vertical_uv\",\n",
    "    }\n",
    "\n",
    "    num_batches = 8\n",
    "    batch_size = 1 # 8\n",
    "    num_batches_probe = 32\n",
    "    batch_size_probe = 1\n",
    "\n",
    "    grad_type = \"dist_sq\"\n",
    "\n",
    "    # lvc_chain = create_lvc(\n",
    "    #     lvc_params,\n",
    "    #     device,\n",
    "    #     False,\n",
    "    #     unsqueeze=True,\n",
    "    #     do_print=do_print,\n",
    "    #     grad_config=None,\n",
    "    #     sionna_config=sionna_config,\n",
    "    # )\n",
    "    # model = get_model(config, device, num_batches, batch_size, lvc_chain=lvc_chain, color_space=color_space, do_print=do_print)\n",
    "    # model.bench()\n",
    "    # return 0\n",
    "    #\n",
    "    # model = get_model(config, device, num_batches, batch_size,color_space=color_space, do_print=do_print)\n",
    "    # res = model.eval()\n",
    "    # print(\"=== orig:\", res)\n",
    "\n",
    "    model_probe = get_model(config, device, num_batches_probe, batch_size_probe, color_space=color_space, do_print=do_print)\n",
    "    res_probe = model_probe.run_probe(grad_type, [nchunks])\n",
    "    # print(\"=== orig probe:\", res_probe)\n",
    "\n",
    "    grad_yuv_key = \"grads_yuv_420\" if yuv_mode == 420 else \"grads_yuv\"\n",
    "    grad_norm_key = \"grads_norm_420\" if yuv_mode == 420 else \"grads_norm\"\n",
    "\n",
    "    # plot_channels(res_probe[grad_yuv_key].numpy(), \"grads YUV\", False, save=\"grads_3.png\", log=True)\n",
    "\n",
    "    if jpeg_config is None or jpeg_config[\"codec\"] != \"grace\":\n",
    "        lvc_chain = create_lvc(\n",
    "            lvc_params,\n",
    "            device,\n",
    "            half=False,\n",
    "            unsqueeze=True,\n",
    "            do_print=do_print,\n",
    "            grad_config=None,\n",
    "            sionna_config=sionna_config,\n",
    "            jpeg_config=jpeg_config,\n",
    "        )\n",
    "\n",
    "        model_lvc = get_model(\n",
    "            config,\n",
    "            device,\n",
    "            num_batches,\n",
    "            batch_size,\n",
    "            num_workers=0,\n",
    "            lvc_chain=lvc_chain,\n",
    "            color_space=color_space,\n",
    "            do_print=do_print\n",
    "        )\n",
    "        res_lvc = model_lvc.eval()\n",
    "        print(\"=== orig LVC:\", res_lvc)\n",
    "\n",
    "\n",
    "    if jpeg_config is None or jpeg_config[\"codec\"] != \"jpeg\":\n",
    "        gconfig: GradConfig = {\n",
    "            \"type\": grad_type,\n",
    "            \"g_yuv\": True,\n",
    "            \"g_select\": True,\n",
    "            \"g_allocate\": True,\n",
    "            \"w\": res_probe[\"W\"],\n",
    "            \"grad_mean\": res_probe[grad_yuv_key],\n",
    "            \"grad_norm\": res_probe[grad_norm_key][nchunks],\n",
    "        }\n",
    "\n",
    "        lvc_chain_g = create_lvc(\n",
    "            lvc_params,\n",
    "            device,\n",
    "            half=False,\n",
    "            unsqueeze=True,\n",
    "            do_print=do_print,\n",
    "            grad_config=gconfig,\n",
    "            sionna_config=sionna_config,\n",
    "            jpeg_config=jpeg_config,\n",
    "        )\n",
    "\n",
    "        model_g = get_model(config, device, num_batches, batch_size, color_space=color_space,\n",
    "                            lvc_chain=lvc_chain_g, do_print=do_print)\n",
    "        res_g = model_g.eval()\n",
    "        print(f\"=== grad LVC: {res_g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# # config:\n",
    "# color_space = \"yuv\"\n",
    "# yuv_mode = 444\n",
    "# nchunks = 256\n",
    "# cr = 1.0 #0.0625\n",
    "# csnr_dbs = [10, 20, 30] #10\n",
    "# estimator = \"zf\"\n",
    "\n",
    "csnr_db = [10, 20, 30]\n",
    "\n",
    "mean_iu = [\n",
    "    0.04296540606173279,\n",
    "    0.20398644323634071,\n",
    "    0.5021734055980513,\n",
    "]\n",
    "\n",
    "mean_iu_g = [\n",
    "    0.04832407239593724,\n",
    "    0.27049837130461907,\n",
    "    0.548599180026712,\n",
    "]\n",
    "\n",
    "plt.title(\"FastSeg (small) mIoU over Sionna channel\")\n",
    "plt.xlabel(\"Eb/N0 [dB]\")\n",
    "plt.ylabel(\"mIoU [-]\")\n",
    "plt.plot(csnr_db, mean_iu, '-+', label=\"miou\")\n",
    "plt.plot(csnr_db, mean_iu_g, '-x', label=\"miou_g\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results notes\n",
    "\n",
    "# === orig: {'mean_iu': 0.6118768412396708, 'val_loss_avg': 0.22068387269973755}\n",
    "\n",
    "# === orig LVC: {'mean_iu': 0.5076176815789921, 'val_loss_avg': 0.09857379645109177}\n",
    "# === grad w grad_norm_select grad_norm_allocate: {'mean_iu': 0.5043232512120162, 'val_loss_avg': 0.1010698452591896}\n",
    "# === orig LVC: {'mean_iu': 0.5076176815789921, 'val_loss_avg': 0.09857379645109177}\n",
    "# === grad w grad_norm_select grad_norm_allocate: {'mean_iu': 0.5042013203125951, 'val_loss_avg': 0.09951619058847427}\n",
    "\n",
    "# === orig LVC: {'mean_iu': 0.5052913375529151, 'val_loss_avg': 0.09825678914785385}\n",
    "# === grad w grad_norm_select grad_norm_allocate: {'mean_iu': 0.5052742168501532, 'val_loss_avg': 0.09825391322374344}\n",
    "# === orig LVC: {'mean_iu': 0.5052913375529151, 'val_loss_avg': 0.09825678914785385}\n",
    "# === grad w grad_norm_select grad_norm_allocate: {'mean_iu': 0.5052803922630612, 'val_loss_avg': 0.09825777262449265}\n",
    "\n",
    "# tensor([-5.1371e-10, -3.4887e-10, -2.2321e-09]  # fastseg\n",
    "# tensor([ 2.9117e-08, -5.7752e-07,  6.6200e-08]  # yolov8\n",
    "\n",
    "# fseg small, 64, 420, 0.5, 10, zf, (all batches):\n",
    "# bilinear:\n",
    "# === orig LVC: {'mean_iu': 0.420771445917225, 'val_loss_avg': 0.5670122504234314}\n",
    "# === grad w grad_norm_select grad_norm_allocate: {'mean_iu': 0.35746933501871525, 'val_loss_avg': 0.7364088892936707}\n",
    "# nearest:\n",
    "# === orig LVC: {'mean_iu': 0.420771445917225, 'val_loss_avg': 0.5670122504234314}\n",
    "# === grad w grad_norm_select grad_norm_allocate: {'mean_iu': 0.3952893112886412, 'val_loss_avg': 0.6174167394638062}\n",
    "# nearest-exact:\n",
    "# === orig LVC: {'mean_iu': 0.420771445917225, 'val_loss_avg': 0.5670122504234314}\n",
    "# === grad w grad_norm_select grad_norm_allocate: {'mean_iu': 0.39431301752844455, 'val_loss_avg': 0.6204946041107178}\n",
    "\n",
    "# cr = 0.0625\n",
    "# orig LVC:\n",
    "# === orig LVC: {'mean_iu': 0.60256914101466, 'val_loss_avg': 0.2260408103466034, 'collected': []}\n",
    "# new:\n",
    "# === grad w grad_norm_select: {'mean_iu': 0.5322282588638082, 'val_loss_avg': 0.30318042635917664, 'collected': []}\n",
    "# new mean abs grad:\n",
    "# === grad w grad_norm_select: {'mean_iu': 0.5023454525660811, 'val_loss_avg': 0.3682572841644287, 'collected': []}\n",
    "# 0.5980870998181766\n",
    "# old:\n",
    "# === grad w grad_norm_select: {'mean_iu': 0.5986947963113816, 'val_loss_avg': 0.23073004186153412, 'collected': []}\n",
    "#\n",
    "# power alloc 10 dB\n",
    "# === orig LVC: {'mean_iu': 0.34010766954194704, 'val_loss_avg': 0.9895051717758179, 'collected': []}\n",
    "# === grad w grad_norm_select grad_norm_allocate: {'mean_iu': 0.3421851648080159, 'val_loss_avg': 1.2698609828948975, 'collected': []}\n",
    "#\n",
    "# num_batches = 8; fastseg small:\n",
    "#         === orig LVC: {'mean_iu': 0.28979775041114986, 'val_loss_avg': 0.9113653302192688, 'collected': []}\n",
    "#      sq === grad type g_yuv g_select g_allocate w grad_mean grad_norm: {'mean_iu': 0.30887477886310216, 'val_loss_avg': 0.9509761929512024, 'collected': []}\n",
    "#     abs === grad type g_yuv g_select g_allocate w grad_mean grad_norm: {'mean_iu': 0.2757566183811295, 'val_loss_avg': 1.4529390335083008, 'collected': []}\n",
    "# precise === grad type g_yuv g_select g_allocate w grad_mean grad_norm: {'mean_iu': 0.3093266004310626, 'val_loss_avg': 0.96988445520401, 'collected': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_channels(res_probe[\"grads_norm\"][nchunks].numpy(), \"grads norm YUV\", show=True, save=None, log=False)\n",
    "# plot_channels(res_probe[\"grads_yuv\"].numpy(), \"grads abs YUV\", show=False, save=None, log=False)\n",
    "# plot_channels(res_probe[\"grads_rgb\"].numpy(), \"grads abs YUV\", show=False, save=None, log=False)\n",
    "# plot_channels(res_probe[\"dct_yuv\"].abs().numpy(), \"dct abs YUV\", show=False, save=None, log=True)\n",
    "# plot_channels(res_probe[\"dct_rgb\"].abs().numpy(), \"dct abs YUV\", show=False, save=None, log=True)\n",
    "print(res_probe.keys())\n",
    "print(res_g)\n",
    "# LVC G loss: 0.5724298357963562\n",
    "# no LVC loss: 0.4200332760810852\n",
    "\n",
    "distortion = (0.5724298357963562 - 0.4200332760810852) ** 2\n",
    "print(distortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing selecting k and cr\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "rows = []\n",
    "for k in range(1, 65):\n",
    "    rows.append(\n",
    "        dict(\n",
    "            k=k,\n",
    "            cr_420_64=k / (64 * 3 / 2),\n",
    "            cr_444_64=k / (64 * 3),\n",
    "            cr_420_256=k / (256 * 3 / 2),\n",
    "            cr_444_256=k / (256 * 3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(pd.DataFrame(rows).to_string())\n",
    "\n",
    "rows = []\n",
    "for cr in [0.025, 0.05, 0.1, 0.2, 0.4, 0.8, 1.0]:\n",
    "    k_420_64 = int(64 * 3 / 2 * cr)\n",
    "    k_444_64 = int(64 * 3 * cr)\n",
    "    k_420_256 = int(256 * 3 / 2 * cr)\n",
    "    k_444_256 = int(256 * 3 * cr)\n",
    "    rows.append(\n",
    "        dict(\n",
    "            cr=cr,\n",
    "            k_420_64=k_420_64,\n",
    "            cr_420_64=k_420_64 / (64 * 3 / 2),\n",
    "            k_444_64=k_444_64,\n",
    "            cr_444_64=k_444_64 / (64 * 3),\n",
    "            k_420_256=k_420_256,\n",
    "            cr_420_256=k_420_256 / (256 * 3 / 2),\n",
    "            k_444_256=k_444_256,\n",
    "            cr_444_256=k_444_256 / (256 * 3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(pd.DataFrame(rows).to_string())\n",
    "\n",
    "rows = []\n",
    "for k in [2, 4, 8, 16, 32, 64, 96]:\n",
    "    rows.append(\n",
    "        dict(\n",
    "            k_420_64=k,\n",
    "            cr_420_64=k / (64 * 3 / 2),\n",
    "            k_444_64=k * 2,\n",
    "            cr_444_64=k * 2 / (64 * 3),\n",
    "            k_420_256=k * 4,\n",
    "            cr_420_256=k * 4 / (256 * 3 / 2),\n",
    "            k_444_256=k * 8,\n",
    "            cr_444_256=k * 8 / (256 * 3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.to_string())\n",
    "\n",
    "fig = px.line(df, x=\"k_420_64\", y=\"cr_420_64\", markers=True)\n",
    "fig.show()\n",
    "\n",
    "rows = []\n",
    "for k in [3, 6, 12, 24, 48, 96]:\n",
    "    rows.append(\n",
    "        dict(\n",
    "            k_420_64=k,\n",
    "            cr_420_64=k / (64 * 3 / 2),\n",
    "            k_444_64=k * 2,\n",
    "            cr_444_64=k * 2 / (64 * 3),\n",
    "            k_420_256=k * 4,\n",
    "            cr_420_256=k * 4 / (256 * 3 / 2),\n",
    "            k_444_256=k * 8,\n",
    "            cr_444_256=k * 8 / (256 * 3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.to_string())\n",
    "\n",
    "fig = px.line(df, x=\"k_420_64\", y=\"cr_420_64\", markers=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "\n",
    "from lvc.lvc import (\n",
    "    YuvImage,\n",
    "    Metadata,\n",
    "    RgbToYcbcrMetadata,\n",
    "    YcbcrToRgbMetadata,\n",
    "    TensorToImage,\n",
    "    ImageToTensor,\n",
    "    DownsampleTensor,\n",
    "    UpsampleTensor,\n",
    ")\n",
    "from models.model import plot_channels\n",
    "from transforms.color_transforms import RgbToYcbcr, YcbcrToRgb\n",
    "from utils import set_device\n",
    "\n",
    "\n",
    "def yuv_image_from_tensor(inp: Tensor, mode: int = 420) -> YuvImage:\n",
    "    if mode != 444 and mode != 420:\n",
    "        raise ValueError(\"Invalid subsampling mode {} (choose 444 or 420)\".format(mode))\n",
    "\n",
    "    if mode == 420:\n",
    "        H = inp.shape[-2]\n",
    "        W = inp.shape[-1]\n",
    "\n",
    "        y, u, v = (x.view((1, 1, H, W)) for x in inp.unbind(-3))\n",
    "\n",
    "        sub_w = int(W / 2)\n",
    "        sub_h = int(H / 2)\n",
    "\n",
    "        u = u[:, :, :sub_h, :sub_w]\n",
    "        v = v[:, :, :sub_h, :sub_w]\n",
    "\n",
    "        return YuvImage(y, u, v)\n",
    "    else:\n",
    "        return YuvImage(inp[0, :, :], inp[1, :, :], inp[2, :, :])\n",
    "\n",
    "\n",
    "gpu_i = 7\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_i}\"\n",
    "device = set_device(f\"cuda:0\")\n",
    "cpus = set(range(84, 96))\n",
    "\n",
    "w_human = torch.Tensor([0.299, 0.587, 0.114])\n",
    "\n",
    "img3 = T.ToTensor()(Image.open(\"/home/jakub/data/kodim/raw/kodim23.png\"))\n",
    "\n",
    "mode = 420\n",
    "\n",
    "fwd = T.Compose([RgbToYcbcr(w=w_human), DownsampleTensor(mode)])\n",
    "\n",
    "bck = T.Compose([UpsampleTensor(mode), YcbcrToRgb(w=w_human)])\n",
    "\n",
    "meta = Metadata(img3.shape[1:], (0, 0), (0, 0))\n",
    "print(meta)\n",
    "\n",
    "# yuv_img = img\n",
    "# for layer in fwd:\n",
    "#     print(\"fwd\", layer)\n",
    "#     yuv_img, meta = layer(yuv_img, meta)\n",
    "#     print(\"yuv_img\", type(yuv_img))\n",
    "# print(yuv_img.shape)\n",
    "\n",
    "# print(\"yuv_img\", type(yuv_img))\n",
    "# res_img = yuv_img\n",
    "\n",
    "# for layer in bck:\n",
    "#     print(\"bck\", layer)\n",
    "#     res_img, meta = layer(res_img, meta)\n",
    "# print(res_img.shape)\n",
    "\n",
    "# print(yuv_img.y[0, 0])\n",
    "# yuv_img = torch.add(yuv_img, yuv_img)\n",
    "# print(yuv_img.y[0, 0])\n",
    "\n",
    "img3 = img3.view((1, img3.shape[-3], img3.shape[-2], img3.shape[-1]))\n",
    "img3.requires_grad_(True)\n",
    "img3.retain_grad()\n",
    "n, c, h, w = img3.shape\n",
    "print(f\"img: {img3.shape}\")\n",
    "# yuv_img = DownsampleTensor(420)(img)\n",
    "\n",
    "yuv_img = fwd(img3)\n",
    "yuv_img2 = RgbToYcbcr(w=w_human)(img3)\n",
    "res_img = bck(yuv_img)\n",
    "res_img2 = YcbcrToRgb(w=w_human)(yuv_img2)\n",
    "\n",
    "yuv_img.requires_grad_(True)\n",
    "yuv_img.retain_grad()\n",
    "yuv_img2.requires_grad_(True)\n",
    "yuv_img2.retain_grad()\n",
    "res_img.requires_grad_(True)\n",
    "res_img.retain_grad()\n",
    "res_img2.requires_grad_(True)\n",
    "res_img2.retain_grad()\n",
    "print(f\"res_img: {res_img.shape}\")\n",
    "\n",
    "\n",
    "# yuv_img.requires_grad_(True)\n",
    "# yuv_img.retain_grad()\n",
    "# yuv_img2 = yuv_img * 2.0\n",
    "# yuv_img, meta = TensorToImage()(img, meta)\n",
    "# yuv_img.retain_grad()\n",
    "\n",
    "# res = yuv_img.mean().sum()\n",
    "# res.requires_grad_(True)\n",
    "# res.retain_grad()\n",
    "\n",
    "tgt = torch.empty((n, h, w), dtype=torch.long).random_(0, 1)\n",
    "crit = nn.LogSoftmax(dim=1)\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "sm = crit(res_img)\n",
    "sm2 = crit(res_img2)\n",
    "print(f\"sm: {sm.shape}\")\n",
    "print(f\"tgt: {tgt.shape}\")\n",
    "loss = loss_fn(sm, tgt)\n",
    "loss2 = loss_fn(sm2, tgt)\n",
    "\n",
    "loss.backward()\n",
    "loss2.backward()\n",
    "\n",
    "print(f\"yuv_img: {yuv_img.shape}\")\n",
    "print(f\"yuv_img grad: {yuv_img.grad.shape}\")\n",
    "print(f\"yuv_img min/max: {yuv_img.grad.min()}/{yuv_img.grad.max()}\")\n",
    "print(\n",
    "    f\"yuv_img Y min/max: {yuv_img.grad[:, 0, :, :].min()}/{yuv_img.grad[:, 0, :, :].max()}\"\n",
    ")\n",
    "\n",
    "\n",
    "# print(loss.grad)\n",
    "# print(res_img.grad)\n",
    "# print(yuv_img.grad)\n",
    "\n",
    "# yuv_img = yuv_image_from_tensor(yuv_img, mode=420)\n",
    "# plot_channels([ch.numpy() for ch in yuv_img.grad.channels()], \"YUV grad\")\n",
    "# plot_channels([ch.detach().numpy() for ch in yuv_img.channels()], \"YUV\")\n",
    "# plot_channels(img.grad.squeeze().numpy(), \"IMG\")\n",
    "plot_channels(yuv_img.grad.squeeze().numpy(), \"YUV\")\n",
    "grad2 = DownsampleTensor(mode)(yuv_img2.grad) * 4\n",
    "plot_channels(grad2.squeeze().numpy(), \"YUV2\")\n",
    "\n",
    "print(yuv_img.grad == grad2)\n",
    "print((yuv_img.grad - grad2).abs().mean())\n",
    "\n",
    "# plot_channels(torch.cat([\n",
    "#     yuv_img.grad.squeeze()[0,:,:],\n",
    "#     yuv_img.grad.squeeze()[1,:,:],\n",
    "#     yuv_img.grad.squeeze()[2,:,:],\n",
    "\n",
    "# ]).numpy(), \"YUV\")\n",
    "# plot_channels(res_img.grad.squeeze().numpy(), \"RES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of parameters\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from models import get_model\n",
    "from utils import set_device\n",
    "\n",
    "device = set_device(f\"cuda:0\")\n",
    "\n",
    "configs = [\n",
    "    {\n",
    "        \"name\": \"yolov8\",\n",
    "        \"variant\": \"n\",\n",
    "        \"task\": \"detect\",\n",
    "        \"snapshot\": f\"yolov8n.pt\",\n",
    "        \"unit\": \"mAP_50_95\",\n",
    "        \"data_file\": \"coco.yaml\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"yolov8\",\n",
    "        \"variant\": \"s\",\n",
    "        \"task\": \"detect\",\n",
    "        \"snapshot\": f\"yolov8s.pt\",\n",
    "        \"unit\": \"mAP_50_95\",\n",
    "        \"data_file\": \"coco.yaml\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"yolov8\",\n",
    "        \"variant\": \"l\",\n",
    "        \"task\": \"detect\",\n",
    "        \"snapshot\": f\"yolov8l.pt\",\n",
    "        \"unit\": \"mAP_50_95\",\n",
    "        \"data_file\": \"coco.yaml\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"fastseg\",\n",
    "        \"variant\": \"small\",\n",
    "        \"snapshot\": (\n",
    "            Path.home() / \"data/models/fastseg/raw/small/best_checkpoint_ep171.pth\"\n",
    "        ),\n",
    "        \"unit\": \"mean_iu\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"fastseg\",\n",
    "        \"variant\": \"large\",\n",
    "        \"snapshot\": (\n",
    "            Path.home() / \"data/models/fastseg/raw/large/best_checkpoint_ep172.pth\"\n",
    "        ),\n",
    "        \"unit\": \"mean_iu\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"Number of parameters:\")\n",
    "for config in configs:\n",
    "    model = get_model(\n",
    "        config,\n",
    "        device,\n",
    "        num_batches=None,\n",
    "        batch_size=8,\n",
    "        color_space=\"yuv\",\n",
    "        do_print=False,\n",
    "    )\n",
    "\n",
    "    print(config[\"name\"], config[\"variant\"], f\"{model.get_num_params() / 1e6:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test JPEG encoding\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from turbojpeg import TurboJPEG, TJSAMP_420, TJPF_RGB, TJSAMP_444\n",
    "\n",
    "from lvc.lvc import ChunkSplit, DctBlock, YuvImage, Metadata\n",
    "from models import get_model, probe_models\n",
    "from models.model import plot_channels\n",
    "from transforms.dct import dct_2d, dct_2d_block\n",
    "from transforms.metrics import mse_psnr\n",
    "from utils import set_device\n",
    "\n",
    "print(\"image:\")\n",
    "img = np.array(Image.open(\"digcom/kodim23.png\"))\n",
    "(img_h, img_w, _) = img.shape\n",
    "print(img.shape)\n",
    "\n",
    "# plt.figure(0)\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "print(\"\")\n",
    "print(\"image yuv 420:\")\n",
    "img2_yuv420 = cv.cvtColor(img, cv.COLOR_RGB2YUV_YV12)\n",
    "print(type(img2_yuv420))\n",
    "print(img2_yuv420.shape)\n",
    "img2 = cv.cvtColor(img2_yuv420, cv.COLOR_YUV2RGB_YV12)\n",
    "print(img2.shape)\n",
    "\n",
    "_, psnr = mse_psnr(torch.tensor(img) / 255.0, torch.tensor(img2) / 255.0)\n",
    "print(psnr)\n",
    "\n",
    "print(\"\")\n",
    "print(\"image yuv 444:\")\n",
    "img2_yuv444 = cv.cvtColor(img, cv.COLOR_RGB2YUV)\n",
    "print(type(img2_yuv444))\n",
    "print(img2_yuv444.shape)\n",
    "img22 = cv.cvtColor(img2_yuv444, cv.COLOR_YUV2RGB)\n",
    "print(img22.shape)\n",
    "\n",
    "_, psnr = mse_psnr(torch.tensor(img) / 255.0, torch.tensor(img22) / 255.0)\n",
    "print(psnr)\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.imshow(img2)\n",
    "# plt.show()\n",
    "\n",
    "jpeg = TurboJPEG(\n",
    "    \"/media/data1/jakub/git/cpc/aisa-demo/external/libjpeg-turbo/libturbojpeg/x86-64/lib/libturbojpeg.so\"\n",
    ")\n",
    "\n",
    "#### This one:\n",
    "\n",
    "q = 80\n",
    "\n",
    "print(\"\")\n",
    "print(\"jpeg yuv:\")\n",
    "jpeg_bytes = jpeg.encode_from_yuv(img2_yuv420, img_h, img_w, q, TJSAMP_420)\n",
    "img3_yuv420, img3_sizes = jpeg.decode_to_yuv(jpeg_bytes)\n",
    "print(type(img3_yuv420))\n",
    "print(\"  decoded:\", img3_yuv420.shape)\n",
    "print(\"  plane sizes:\", img3_sizes)\n",
    "img3_rgb = cv.cvtColor(img3_yuv420.reshape(img_w, img_w), cv.COLOR_YUV2RGB_YV12)\n",
    "mse, psnr = mse_psnr(torch.tensor(img) / 255.0, torch.tensor(img3_rgb) / 255.0)\n",
    "print(f\"RGB          : MSE {mse:.3e}, PSNR {psnr:.3f} dB\")\n",
    "# TODO: These are not correct because opencv and turbojpeg YUV transforms are not\n",
    "# compatible.\n",
    "mse, psnr = mse_psnr(\n",
    "    torch.tensor(img2_yuv420) / 255.0,\n",
    "    torch.tensor(img3_yuv420.reshape(img_w, img_w)) / 255.0,\n",
    ")\n",
    "print(f\"YUV          : MSE {mse:.3e}, PSNR {psnr:.3f} dB\")\n",
    "plt.imsave(\"img3_rgb.png\", img3_rgb)\n",
    "\n",
    "#### With no subsampling (distorted for some reason):\n",
    "\n",
    "q = 80\n",
    "\n",
    "print(\"\")\n",
    "print(\"jpeg yuv 444:\")\n",
    "jpeg_bytes = jpeg.encode_from_yuv(img2_yuv444, img_h, img_w, q, TJSAMP_444)\n",
    "img3_yuv444, img33_sizes = jpeg.decode_to_yuv(jpeg_bytes)\n",
    "print(type(img3_yuv444))\n",
    "print(\"  decoded:\", img3_yuv444.shape)\n",
    "print(\"  plane sizes:\", img33_sizes)\n",
    "img33_rgb = cv.cvtColor(img3_yuv444.reshape(img_h, img_w, 3), cv.COLOR_YUV2RGB)\n",
    "print(\"  rgb size\", img33_rgb.shape)\n",
    "mse, psnr = mse_psnr(torch.tensor(img) / 255.0, torch.tensor(img33_rgb) / 255.0)\n",
    "print(f\"RGB          : MSE {mse:.3e}, PSNR {psnr:.3f} dB\")\n",
    "# TODO: These are not correct because opencv and turbojpeg YUV transforms are not\n",
    "# compatible.\n",
    "mse, psnr = mse_psnr(\n",
    "    torch.tensor(img2_yuv444) / 255.0,\n",
    "    torch.tensor(img3_yuv444.reshape(img_h, img_w, 3)) / 255.0,\n",
    ")\n",
    "print(f\"YUV444       : MSE {mse:.3e}, PSNR {psnr:.3f} dB\")\n",
    "plt.imsave(\"img3_rgb_444.png\", img33_rgb)\n",
    "\n",
    "### This one somehow loses color?\n",
    "\n",
    "print(\"\")\n",
    "print(\"jpeg rgb:\")\n",
    "img4_rgb = jpeg.decode(jpeg_bytes)\n",
    "print(type(img4_rgb))\n",
    "print(img4_rgb.shape)\n",
    "mse, psnr = mse_psnr(torch.tensor(img) / 255.0, torch.tensor(img4_rgb) / 255.0)\n",
    "print(f\"RGB          : MSE {mse:.3e}, PSNR {psnr:.3f} dB\")\n",
    "mse, psnr = mse_psnr(torch.tensor(img3_rgb) / 255.0, torch.tensor(img4_rgb) / 255.0)\n",
    "print(f\"RGB (vs YUV) : MSE {mse:.3e}, PSNR {psnr:.3f} dB\")\n",
    "plt.imsave(\"img4_rgb.png\", img4_rgb)\n",
    "\n",
    "# w_human_rgb = torch.Tensor((0.299, 0.587, 0.114))\n",
    "# w_img3_yuv420 = torch.tensor(img3_yuv420) / 255.0\n",
    "# w_img3_yuv420[:img_w * img_h] *= w_human[0]\n",
    "# w_img3_yuv420[img_w * img_h : img_w * img_h + (img_w * img_h // 4)] *= w_human[1]\n",
    "# w_img3_yuv420[img_w * img_h + (img_w * img_h // 4):] *= w_human[2]\n",
    "# w_img3_yuv420 = w_img3_yuv420.reshape(img_w, img_w)\n",
    "# mse, psnr = mse_psnr(\n",
    "#     torch.tensor(img2_yuv420) / 255.0,\n",
    "#     w_img3_yuv420,\n",
    "# )\n",
    "# print(f\"YUV weighted : MSE {mse:.3e}, PSNR {psnr:.3f} dB\")\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.imshow(img3_rgb)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "print(\"\")\n",
    "dct_size = (32, 32)\n",
    "\n",
    "try:\n",
    "    print(list(result_probe.keys()))\n",
    "    grad_yuv420_norm = result_probe[\"grads_norm_420\"][dct_size[0] * dct_size[1]].numpy()\n",
    "    grad_yuv420 = result_probe[\"grads_yuv_420\"].numpy()\n",
    "    grad_rgb = result_probe[\"grads_rgb\"]\n",
    "    W = result_probe[\"W\"]\n",
    "except:\n",
    "    torch.manual_seed(42)\n",
    "    gpu_i = 0\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_i}\"\n",
    "    # device = set_device(f\"cuda:0\")\n",
    "    device = set_device(f\"cpu\")\n",
    "    # cpus = set(range(84, 96))\n",
    "    # os.sched_setaffinity(0, cpus)\n",
    "    # affinity = os.sched_getaffinity(0)\n",
    "    # print(f\"Running on CPUs: {affinity}\")\n",
    "    # torch.set_num_threads(len(cpus))\n",
    "\n",
    "    color_space = \"yuv\"\n",
    "    modes = [444]  # , 420]\n",
    "    num_batches_probe = 32\n",
    "    batch_size_probe = 1\n",
    "\n",
    "    config = {\n",
    "        \"name\": \"yolov8\",\n",
    "        \"variant\": \"n\",\n",
    "        \"snapshot\": \"yolov8n.pt\",\n",
    "        \"unit\": \"mAP_50_95\",\n",
    "        \"task\": \"detect\",\n",
    "        \"data_file\": \"coco.yaml\",\n",
    "    }\n",
    "\n",
    "    model_probe = get_model(\n",
    "        config, device, num_batches_probe, batch_size_probe, color_space=\"yuv\"\n",
    "    )\n",
    "\n",
    "    result_probe = model_probe.run_probe(\"dist_sq\", [64, 256, 1024])\n",
    "    print(list(result_probe.keys()))\n",
    "    grad_yuv420_norm = result_probe[\"grads_norm_420\"][dct_size[0] * dct_size[1]].numpy()\n",
    "    grad_yuv420 = result_probe[\"grads_yuv_420\"].numpy()\n",
    "    grad_rgb = result_probe[\"grads_rgb\"]\n",
    "    W = result_probe[\"W\"]\n",
    "\n",
    "\n",
    "# plot_channels(grad_yuv420_norm, \"Norm sq grad YUV 420 block\", show=True)\n",
    "\n",
    "### YUV\n",
    "\n",
    "print(\"\")\n",
    "y3, u3, v3 = jpeg.decode_to_yuv_planes(jpeg_bytes)\n",
    "y3 = torch.tensor(y3) / 255.0\n",
    "u3 = torch.tensor(u3) / 255.0\n",
    "v3 = torch.tensor(v3) / 255.0\n",
    "\n",
    "norm = \"ortho\"\n",
    "dct_y = dct_2d_block(\n",
    "    y3.unsqueeze(0).unsqueeze(0), norm, dct_size[0], dct_size[1]\n",
    ").squeeze()\n",
    "dct_u = dct_2d_block(\n",
    "    u3.unsqueeze(0).unsqueeze(0), norm, dct_size[0], dct_size[1]\n",
    ").squeeze()\n",
    "dct_v = dct_2d_block(\n",
    "    v3.unsqueeze(0).unsqueeze(0), norm, dct_size[0], dct_size[1]\n",
    ").squeeze()\n",
    "\n",
    "print(\"grads norm yuv420: \", grad_yuv420_norm.shape)\n",
    "print(\"grads yuv420: \", grad_yuv420.shape)\n",
    "print(\"grads rgb: \", grad_rgb.shape)\n",
    "print(\"W:\", W)\n",
    "print(\"DCT Y: \", dct_y.shape)\n",
    "print(\"DCT U: \", dct_u.shape)\n",
    "print(\"DCT V: \", dct_v.shape)\n",
    "\n",
    "plt.imsave(\"dct_y.png\", dct_y.square().mean(dim=0).log10().numpy())\n",
    "plt.imsave(\"dct_u.png\", dct_u.square().mean(dim=0).log10().numpy())\n",
    "plt.imsave(\"dct_v.png\", dct_v.square().mean(dim=0).log10().numpy())\n",
    "plt.imsave(\"grad_norm_y.png\", grad_yuv420_norm[0])\n",
    "plt.imsave(\"grad_norm_u.png\", grad_yuv420_norm[1])\n",
    "plt.imsave(\"grad_norm_v.png\", grad_yuv420_norm[2])\n",
    "\n",
    "### RGB\n",
    "\n",
    "print(\"\")\n",
    "metadata = Metadata(\n",
    "    (grad_rgb.shape[1], grad_rgb.shape[2]),\n",
    "    dct_size,\n",
    "    (grad_rgb.shape[1] // dct_size[0], grad_rgb.shape[2] // dct_size[1]),\n",
    ")\n",
    "data = YuvImage(grad_rgb[0, :, :], grad_rgb[1, :, :], grad_rgb[2, :, :])\n",
    "grad_rgb_chunks, _ = ChunkSplit(dct_size)(data, metadata)\n",
    "print(\"grad_rgb_chunks: \", grad_rgb_chunks.shape)\n",
    "nchunks = grad_rgb_chunks.shape[0]\n",
    "grad_rgb_chunks_r = grad_rgb_chunks[: nchunks // 3]\n",
    "grad_rgb_chunks_g = grad_rgb_chunks[nchunks // 3 : 2 * nchunks // 3]\n",
    "grad_rgb_chunks_b = grad_rgb_chunks[3 * nchunks // 3 :]\n",
    "\n",
    "grad_rgb_norm = torch.stack(\n",
    "    [\n",
    "        grad_rgb_chunks_r.mean(dim=0),\n",
    "        grad_rgb_chunks_g.mean(dim=0),\n",
    "        grad_rgb_chunks_b.mean(dim=0),\n",
    "    ]\n",
    ")\n",
    "print(\"grad_rgb_norm: \", grad_rgb_norm.shape)\n",
    "\n",
    "grad_norm_r = grad_rgb_norm[0, :, :]\n",
    "grad_norm_g = grad_rgb_norm[1, :, :]\n",
    "grad_norm_b = grad_rgb_norm[2, :, :]\n",
    "print(\"grad norm 1ch: \", grad_norm_r.shape, grad_norm_g.shape, grad_norm_b.shape)\n",
    "\n",
    "rgb = (torch.tensor(img3_rgb) / 255.0).permute((2, 0, 1))\n",
    "\n",
    "r = rgb[0, :, :]\n",
    "g = rgb[1, :, :]\n",
    "b = rgb[2, :, :]\n",
    "\n",
    "dct_r = dct_2d_block(\n",
    "    r.unsqueeze(0).unsqueeze(0), norm, dct_size[0], dct_size[1]\n",
    ").squeeze()\n",
    "dct_g = dct_2d_block(\n",
    "    g.unsqueeze(0).unsqueeze(0), norm, dct_size[0], dct_size[1]\n",
    ").squeeze()\n",
    "dct_b = dct_2d_block(\n",
    "    b.unsqueeze(0).unsqueeze(0), norm, dct_size[0], dct_size[1]\n",
    ").squeeze()\n",
    "print(\"dct_rgb: \", dct_r.shape, dct_g.shape, dct_b.shape)\n",
    "\n",
    "ref_rgb = (torch.tensor(img) / 255.0).permute((2, 0, 1))\n",
    "\n",
    "ref_r = ref_rgb[0, :, :]\n",
    "ref_g = ref_rgb[1, :, :]\n",
    "ref_b = ref_rgb[2, :, :]\n",
    "\n",
    "ref_dct_r = dct_2d_block(\n",
    "    ref_r.unsqueeze(0).unsqueeze(0), norm, dct_size[0], dct_size[1]\n",
    ").squeeze()\n",
    "ref_dct_g = dct_2d_block(\n",
    "    ref_g.unsqueeze(0).unsqueeze(0), norm, dct_size[0], dct_size[1]\n",
    ").squeeze()\n",
    "ref_dct_b = dct_2d_block(\n",
    "    ref_b.unsqueeze(0).unsqueeze(0), norm, dct_size[0], dct_size[1]\n",
    ").squeeze()\n",
    "print(\"ref_dct_rgb: \", ref_dct_r.shape, ref_dct_g.shape, ref_dct_b.shape)\n",
    "\n",
    "mse, psnr = mse_psnr(ref_rgb, rgb)\n",
    "print(f\"DCT RGB      : MSE {mse:.3e}, PSNR {psnr:.3f} dB\")\n",
    "\n",
    "er = ((dct_r - ref_dct_r).square() * grad_norm_r).mean()\n",
    "eg = ((dct_g - ref_dct_g).square() * grad_norm_g).mean()\n",
    "eb = ((dct_b - ref_dct_b).square() * grad_norm_b).mean()\n",
    "\n",
    "print(\"err grad dct rgb: \", er, eg, eb)\n",
    "\n",
    "\n",
    "# TODO: compare each plane separately and weigh them accurding to W\n",
    "# mse, psnr = mse_psnr( ...\n",
    "\n",
    "# yuv3_420 = YuvImage(y3, u3, v3)\n",
    "\n",
    "# split = ChunkSplit(dct_size)\n",
    "# metadata = Metadata((img_w, img_h), dct_size, 0)\n",
    "\n",
    "# blocks, _ = split(yuv3_420, metadata)\n",
    "# print(\"blocks: \", blocks.shape)\n",
    "\n",
    "# dct_blocks = dct_2d(blocks)\n",
    "# print(dct_blocks.shape)\n",
    "\n",
    "# mode = 420\n",
    "# dct_block = DctBlock(\n",
    "#     dct_size,\n",
    "#     mode,\n",
    "#     ???\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import ortho_group, special_ortho_group\n",
    "from scipy.io import savemat\n",
    "from PIL import Image\n",
    "\n",
    "from transforms.dct import dct_2d, idct_2d\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "x = (\n",
    "    torch.tensor(np.asarray(Image.open(\"backup/kodim23.png\").convert(\"L\"), dtype=float))\n",
    "    / 255.0\n",
    ")\n",
    "x = x - x.mean()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"x\")\n",
    "plt.imshow(x, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "n = 8\n",
    "(h, w) = x.shape\n",
    "\n",
    "if (w % n != 0) or (h % n != 0):\n",
    "    raise ValueError(\"Invalid n\")\n",
    "\n",
    "wch = w // n\n",
    "hch = h // n\n",
    "N = n * n\n",
    "nbins = N\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"x hist\")\n",
    "plt.hist(x.reshape(-1), bins=nbins)\n",
    "plt.show()\n",
    "\n",
    "X = dct_2d(x)\n",
    "\n",
    "Xch = X.unfold(0, hch, hch).unfold(1, wch, wch).reshape((-1, hch, wch))\n",
    "print(\"Xch\", Xch.shape)\n",
    "savemat(\"Xch.mat\", {\"Xch\": Xch.reshape(N, -1).detach().cpu().numpy()})\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"X energy\")\n",
    "plt.bar(np.arange(N), Xch.square().mean((1, 2)))\n",
    "plt.yscale(\"log\")\n",
    "# plt.hist(X.reshape(-1), bins=nbins)\n",
    "plt.show()\n",
    "\n",
    "H = torch.empty(N, N).type_as(Xch)\n",
    "nn.init.orthogonal_(H)\n",
    "# H = (H - H.mean()) / H.std()\n",
    "print(\"H mean\", H.mean(), \"std\", H.std())\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"H\")\n",
    "plt.imshow(H)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"H hist\")\n",
    "plt.hist(H.reshape(-1), bins=nbins)\n",
    "plt.show()\n",
    "\n",
    "Y = torch.matmul(H, Xch.reshape(N, -1)).reshape(Xch.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Y energy\")\n",
    "plt.bar(np.arange(N), Y.square().mean((1, 2)))\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Y hist\")\n",
    "plt.hist(Y.reshape(-1), bins=nbins)\n",
    "plt.show()\n",
    "\n",
    "# trying to convert normal to uniform (CDF of normal is uniform)\n",
    "J = (1 / 2) * (1 + torch.erf((H - H.mean()) / (H.std() * math.sqrt(2))))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"J\")\n",
    "plt.imshow(J)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"J hist\")\n",
    "plt.hist(J.reshape(-1), bins=nbins)\n",
    "plt.show()\n",
    "\n",
    "# Z = J * X\n",
    "Z = torch.matmul(J, Xch.reshape(N, -1)).reshape(Xch.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Z energy\")\n",
    "plt.bar(np.arange(N), Z.square().mean((1, 2)))\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Z hist\")\n",
    "plt.hist(Z.reshape(-1), bins=nbins)\n",
    "plt.show()\n",
    "\n",
    "W = idct_2d(Xch.reshape((N, -1))).reshape(Xch.shape)\n",
    "# W = torch.empty(Xch.shape)\n",
    "# for i in range(W.shape[0]):\n",
    "#     W[i, :, :] = idct_2d(Xch[i])\n",
    "print(\"W:\", W.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"W energy\")\n",
    "plt.bar(np.arange(N), W.square().mean((1, 2)))\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"W hist\")\n",
    "plt.hist(W.reshape(-1), bins=nbins)\n",
    "plt.show()\n",
    "\n",
    "O = torch.tensor(ortho_group.rvs(N))\n",
    "print(np.dot(O, O.T))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"O\")\n",
    "plt.imshow(O)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"O hist\")\n",
    "plt.hist(O.reshape(-1), bins=nbins)\n",
    "plt.show()\n",
    "\n",
    "# Q = torch.tensor(O) * X\n",
    "Q = torch.matmul(O, Xch.reshape(N, -1)).reshape(Xch.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Q energy\")\n",
    "plt.bar(np.arange(N), Q.square().mean((1, 2)))\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Q hist\")\n",
    "plt.hist(Q.reshape(-1), bins=nbins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "\n",
    "\n",
    "def rand_ortho(n: int) -> torch.Tensor:\n",
    "    A = torch.zeros(n, n, dtype=torch.float64)\n",
    "\n",
    "    vals = torch.tensor([1, -1])\n",
    "    row = torch.zeros(1, n)\n",
    "\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        idx = torch.randint(0, 2, row.shape)\n",
    "        A[i] = vals[idx]\n",
    "        rank = torch.linalg.matrix_rank(A)\n",
    "\n",
    "        if rank == i + 1:\n",
    "            i += 1\n",
    "\n",
    "    U, _, _ = torch.linalg.svd(A)\n",
    "    U = U / U.square().sum(dim=1).sqrt()\n",
    "\n",
    "    return U\n",
    "\n",
    "\n",
    "# For comparison with MATLAB version:\n",
    "# n = 8\n",
    "\n",
    "# A = torch.zeros(n, n)\n",
    "\n",
    "# vals = torch.tensor([1, -1])\n",
    "# row = torch.zeros(1, n)\n",
    "\n",
    "# A_rows = torch.tensor([\n",
    "#    [-1,    1,   -1,    1,   -1,    1,    1,   -1 ],\n",
    "#    [-1,    1,    1,    1,    1,   -1,   -1,   -1 ],\n",
    "#    [ 1,    1,   -1,   -1,   -1,   -1,    1,    1 ],\n",
    "#    [ 1,   -1,   -1,    1,    1,    1,    1,   -1 ],\n",
    "#    [ 1,   -1,   -1,   -1,   -1,    1,   -1,    1 ],\n",
    "#    [ 1,   -1,   -1,    1,   -1,   -1,   -1,   -1 ],\n",
    "#    [ 1,    1,    1,    1,    1,   -1,    1,    1 ],\n",
    "#    [ 1,    1,   -1,   -1,   -1,   -1,    1,    1 ],\n",
    "#    [-1,    1,   -1,   -1,   -1,   -1,    1,   -1 ],\n",
    "#    [ 1,    1,   -1,    1,    1,   -1,   -1,   -1 ],\n",
    "#    [-1,   -1,    1,    1,   -1,   -1,    1,   -1 ],\n",
    "#    [-1,   -1,    1,   -1,    1,    1,   -1,    1 ],\n",
    "# ])\n",
    "# iA = 0\n",
    "\n",
    "# i = 0\n",
    "# while i < n:\n",
    "#     idx = torch.randint(0, 2, row.shape)\n",
    "#     # print(idx)\n",
    "#     # A[i] = vals[idx]\n",
    "#     A[i] = A_rows[iA]\n",
    "#     iA += 1\n",
    "\n",
    "#     rank = torch.linalg.matrix_rank(A)\n",
    "#     print(rank)\n",
    "\n",
    "#     if rank == i + 1:\n",
    "#         i += 1\n",
    "\n",
    "\n",
    "# Aref = torch.tensor([\n",
    "#     -1,    1,   -1,    1,   -1,    1,    1,   -1,\n",
    "#     -1,    1,    1,    1,    1,   -1,   -1,   -1,\n",
    "#      1,    1,   -1,   -1,   -1,   -1,    1,    1,\n",
    "#      1,   -1,   -1,    1,    1,    1,    1,   -1,\n",
    "#      1,   -1,   -1,   -1,   -1,    1,   -1,    1,\n",
    "#      1,   -1,   -1,    1,   -1,   -1,   -1,   -1,\n",
    "#      1,    1,    1,    1,    1,   -1,    1,    1,\n",
    "#     -1,   -1,    1,   -1,    1,    1,   -1,    1,\n",
    "# ], dtype=float).reshape(n, n)\n",
    "\n",
    "# print(\"A:\", A)\n",
    "# print(\"A == Aref: \", (A == Aref).all().item())\n",
    "\n",
    "# U, S, Vh = torch.linalg.svd(A)\n",
    "\n",
    "Osvd = rand_ortho(N)\n",
    "print(np.dot(Osvd, Osvd.T))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Osvd\")\n",
    "plt.imshow(Osvd)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Osvd hist\")\n",
    "plt.hist(Osvd.reshape(-1), bins=nbins)\n",
    "plt.show()\n",
    "\n",
    "print(Xch.dtype)\n",
    "Osvd_res = torch.matmul(Osvd, Xch.reshape(N, -1)).reshape(Xch.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Osvd result energy\")\n",
    "plt.bar(np.arange(N), Osvd_res.square().mean((1, 2)))\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Osvd result hist\")\n",
    "plt.hist(Osvd_res.reshape(-1), bins=nbins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "print(sio.loadmat(\"reference/H48.mat\")[\"H\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
