{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run lvc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from lvc import allowed_image_sizes\n",
    "\n",
    "allowed_image_sizes((44, 36), mode=420, cr=0.25, min_dim=200, max_dim=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from lvc import YuvImage, run_yuv420\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "frame_mats = [\n",
    "    sio.loadmat(\"reference/kodim23_cif_frame01.mat\"),\n",
    "    sio.loadmat(\"reference/husky_cif_frame01.mat\"),\n",
    "]\n",
    "\n",
    "yuv_images_inp = [\n",
    "    YuvImage(\n",
    "        torch.Tensor(frame_mat[\"first_Y\"]) / 255.0,\n",
    "        torch.Tensor(frame_mat[\"first_U\"]) / 255.0,\n",
    "        torch.Tensor(frame_mat[\"first_V\"]) / 255.0,\n",
    "    )\n",
    "    for frame_mat in frame_mats\n",
    "]\n",
    "\n",
    "crs = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "csnr_dbs = [-5, 0, 5, 10, 15, 20, 25, 30, 35, \"inf\"]\n",
    "chunk_size = (36, 44)\n",
    "\n",
    "res_zf = run_yuv420(crs, csnr_dbs, yuv_images_inp, chunk_size, \"zf\")\n",
    "res_llse = run_yuv420(crs, csnr_dbs, yuv_images_inp, chunk_size, \"llse\")\n",
    "\n",
    "report_n = 0\n",
    "\n",
    "plot_style_zf = {\n",
    "    \"marker\" : \"+\",\n",
    "    \"markersize\" : 15,\n",
    "    \"label\": \"ZF\",\n",
    "}\n",
    "plot_style_llse = {\n",
    "    \"marker\" : \"x\",\n",
    "    \"markersize\" : 15,\n",
    "    \"label\": \"LLSE\",\n",
    "}\n",
    "\n",
    "psnrs_zf = [\n",
    "    [res_zf[(cr, \"inf\")][report_n][0] for cr in crs],\n",
    "    [res_zf[(cr, \"inf\")][report_n][1] for cr in crs],\n",
    "    [res_zf[(cr, \"inf\")][report_n][2] for cr in crs],\n",
    "]\n",
    "psnrs_llse = [\n",
    "    [res_llse[(cr, \"inf\")][report_n][0] for cr in crs],\n",
    "    [res_llse[(cr, \"inf\")][report_n][1] for cr in crs],\n",
    "    [res_llse[(cr, \"inf\")][report_n][2] for cr in crs],\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 20))\n",
    "fig.suptitle(\"PSNR vs CR\")\n",
    "axs = axs.flatten()\n",
    "for i, title in enumerate([\"Y\", \"U\", \"V\"]):\n",
    "    axs[i].plot(csnr_dbs, psnrs_zf[i], **plot_style_zf),\n",
    "    axs[i].plot(csnr_dbs, psnrs_llse[i], **plot_style_llse),\n",
    "    axs[i].set_title(title)\n",
    "    axs[i].legend()\n",
    "    axs[i].set_ylim(ymax=70)\n",
    "    axs[i].set_xlabel(\"CSNR (dB)\")\n",
    "    axs[i].set_ylabel(\"PSNR (dB)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "psnrs_zf = [\n",
    "    [res_zf[(1.0, csnr_db)][report_n][0] for csnr_db in csnr_dbs],\n",
    "    [res_zf[(1.0, csnr_db)][report_n][1] for csnr_db in csnr_dbs],\n",
    "    [res_zf[(1.0, csnr_db)][report_n][2] for csnr_db in csnr_dbs],\n",
    "]\n",
    "psnrs_llse = [\n",
    "    [res_llse[(1.0, csnr_db)][report_n][0] for csnr_db in csnr_dbs],\n",
    "    [res_llse[(1.0, csnr_db)][report_n][1] for csnr_db in csnr_dbs],\n",
    "    [res_llse[(1.0, csnr_db)][report_n][2] for csnr_db in csnr_dbs],\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 20))\n",
    "fig.suptitle(\"PSNR vs CSNR\")\n",
    "axs = axs.flatten()\n",
    "for i, title in enumerate([\"Y\", \"U\", \"V\"]):\n",
    "    axs[i].plot(csnr_dbs, psnrs_zf[i], **plot_style_zf),\n",
    "    axs[i].plot(csnr_dbs, psnrs_llse[i], **plot_style_llse),\n",
    "    axs[i].set_title(title)\n",
    "    axs[i].legend()\n",
    "    axs[i].set_ylim(ymax=70)\n",
    "    axs[i].set_xlabel(\"CSNR (dB)\")\n",
    "    axs[i].set_ylabel(\"PSNR (dB)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from lvc import run_rgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_dir = Path(\"C:/kubouch/data/kodim/raw\")\n",
    "\n",
    "rgb_images_inp = list(img_dir.glob(\"*.png\"))\n",
    "\n",
    "crs = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "csnr_dbs = [0, 10, 20, 30, \"inf\"]\n",
    "chunk_size = (36, 44)\n",
    "\n",
    "res = run_rgb(crs, csnr_dbs, rgb_images_inp, chunk_size)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from lvc import create_lvc\n",
    "from utils import set_device\n",
    "\n",
    "device = set_device()\n",
    "\n",
    "img_dir = Path(\"C:/kubouch/data/kodim/raw\")\n",
    "image_names = list(img_dir.glob(\"*.png\"))\n",
    "images = torch.stack([\n",
    "    # transforms.CenterCrop((288, 352))(\n",
    "    transforms.Resize((512, 768))(\n",
    "    # transforms.Resize((288, 672))(\n",
    "        transforms.ToTensor()(\n",
    "            Image.open(image_name).convert(mode=\"RGB\")\n",
    "        )\n",
    "    )\n",
    "    for image_name in image_names\n",
    "])\n",
    "print(\"Images: \", images.shape)\n",
    "\n",
    "lvc_params_zf = {\n",
    "    \"csnr_db\": 30,\n",
    "    \"cr\": 1.0,\n",
    "    \"mode\": 420,\n",
    "    # \"chunk_w\": 32,\n",
    "    # \"chunk_h\": 32,\n",
    "    \"nchunks\": 256,\n",
    "    \"seed\": 42,\n",
    "    \"estimator\": \"zf\",  # llse\n",
    "    \"packet_loss\": None, #0.0,\n",
    "    \"dct_w\": 16,\n",
    "    \"dct_h\": 16,\n",
    "    \"grouping\": \"vertical_uv\",\n",
    "}\n",
    "\n",
    "lvc_params_llse = lvc_params_zf\n",
    "lvc_params_llse[\"estimator\"] = \"llse\"\n",
    "\n",
    "lvc_zf = create_lvc(lvc_params_zf, device, half=False)\n",
    "lvc_llse = create_lvc(lvc_params_llse, device, half=False)\n",
    "\n",
    "res_zf = lvc_zf(images)\n",
    "res_llse = lvc_llse(images)\n",
    "print(\"Result: \", res_zf.shape)\n",
    "\n",
    "psnr = 10 * torch.log10(1.0 / (res_zf - images).square().mean())\n",
    "print(\"ZF PSNR:\", psnr)\n",
    "\n",
    "mse = (res_llse - res_zf).square().mean()\n",
    "print(\"MSE LSE vs ZF:\", mse)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(20, 20))\n",
    "fig.suptitle(\"Output image\")\n",
    "axs.imshow(transforms.ToPILImage()(res_zf[22]))\n",
    "axs.set_title(\"RGB ZF\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "torch.manual_seed(7)\n",
    "\n",
    "N = 4\n",
    "w1 = torch.empty(N, N)\n",
    "w2 = torch.empty(N, N)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"init_orthogonal\"):\n",
    "        nn.init.orthogonal_(w1)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "# Also:\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ortho_group.html?highlight=ortho_group#scipy.stats.ortho_group\n",
    "\n",
    "print(torch.matmul(w1, w1.T))\n",
    "\n",
    "torch.manual_seed(7)\n",
    "nn.init.orthogonal_(w2)\n",
    "print(\"diff: \", (w1 - w2).abs().mean())\n",
    "\n",
    "x = torch.rand(4)\n",
    "print(w1 @ x)\n",
    "print(x @ w1)\n",
    "print(x)\n",
    "print(w1.T @ (w1 @ x))\n",
    "print((x @ w1) @ w1.T)\n",
    "\n",
    "y = torch.rand(2, 3)\n",
    "Y = torch.stack([y, y, y, y])\n",
    "YY = Y.permute((1, 2, 0)).unsqueeze(3)\n",
    "print(YY.shape)\n",
    "YY = torch.matmul(w1, YY)\n",
    "YYY = torch.matmul(w1.T, YY).squeeze().permute(2, 0, 1)\n",
    "\n",
    "# z = torch.arange(6).reshape(2,3)\n",
    "# z  = torch.stack([z, z, z, z]).permute((1,2,0)).unsqueeze(3)\n",
    "# wz = torch.arange(16).reshape(4,4)\n",
    "# Z = torch.matmul(wz, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import scipy.io as sio\n",
    "\n",
    "from lvc import LlseEstimate, Metadata\n",
    "\n",
    "noise_power = torch.tensor(sio.loadmat(\"reference/sigma_noise.mat\")[\"sigma_bruit\"]).square().squeeze()\n",
    "variances = torch.tensor(sio.loadmat(\"reference/var.mat\")[\"Lambdan\"]).squeeze()\n",
    "llse_in  = torch.tensor(sio.loadmat(\"reference/LLSE_in.mat\")[\"Tn\"]).reshape(-1, 36, 44)\n",
    "llse_mat = torch.tensor(sio.loadmat(\"reference/LLSE_mat.mat\")[\"Hn\"])\n",
    "llse_out = torch.tensor(sio.loadmat(\"reference/LLSE_out.mat\")[\"X_hatNa\"]).reshape(-1, 36, 44)\n",
    "\n",
    "metadata = Metadata((288, 352), (36, 44))\n",
    "metadata.set_variances(variances)\n",
    "metadata.set_noise_power(noise_power)\n",
    "power = 1.0\n",
    "\n",
    "out_tensor, out_metadata = LlseEstimate(power)(llse_in, metadata)\n",
    "\n",
    "print(\"LLSE estimation vs. Matlab MAE: \", (llse_out - out_tensor).abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import scipy.io as sio\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lvc import LvcEncode, RgbToYcbcr, Downsample, SubtractMean, DCT, DctBlock, ChunkSelect, LvcDecode, IDCT, IdctBlock, ChunkRestore, ChunkCombine, RestoreMean, ChunkSplit, Channel, Upsample, YcbcrToRgbMetadata, RgbToYcbcrMetadata, Pad, Crop, PowerAllocate, RandomOrthogonal, ZfEstimate, LlseEstimate\n",
    "\n",
    "from utils import set_device\n",
    "\n",
    "image_inp = transforms.ToTensor()(Image.open(\"C:/kubouch/data/mini/kodim23_48x48.png\"))\n",
    "\n",
    "references = None\n",
    "results = None\n",
    "norm = 'ortho'\n",
    "do_print = True\n",
    "device = set_device()\n",
    "\n",
    "w_human = torch.Tensor([0.299, 0.587, 0.114])\n",
    "yuv_mode = 420\n",
    "dct_size = (8, 8)\n",
    "chunk_size = 64\n",
    "snr_db = 30\n",
    "packet_loss = None #0.5\n",
    "seed = 42\n",
    "cr = 1.0 #0.25\n",
    "# grouping = \"vertical_uv\"\n",
    "grouping = \"horizontal_uv\"\n",
    "power = 1.0\n",
    "\n",
    "lvc_encoder = LvcEncode(\n",
    "    [\n",
    "        Pad(420, dct_size, do_print=do_print),\n",
    "        RgbToYcbcrMetadata(w_human),\n",
    "        Downsample(mode=yuv_mode),\n",
    "        SubtractMean(device),\n",
    "        # DCT(is_half=False, norm=norm),\n",
    "        ChunkSplit(dct_size, do_print=do_print),\n",
    "        DctBlock(dct_size, yuv_mode, grouping, is_half=False, norm=norm, do_print=do_print),\n",
    "        ChunkSelect(cr, do_print=do_print),\n",
    "        PowerAllocate(power, do_print=do_print),\n",
    "        RandomOrthogonal(seed, device, invert=False),\n",
    "    ],\n",
    "    references,\n",
    "    results,\n",
    "    chunk_size,\n",
    "    do_print=do_print,\n",
    ")\n",
    "\n",
    "lvc_decoder = LvcDecode(\n",
    "    [\n",
    "        RandomOrthogonal(seed, device, invert=True),\n",
    "        ZfEstimate(power),\n",
    "        # LlseEstimate(power),\n",
    "        ChunkRestore(device=device, is_half=False, do_print=do_print),\n",
    "        IdctBlock(dct_size, yuv_mode, grouping, is_half=False, norm=norm, do_print=do_print),\n",
    "        ChunkCombine(\n",
    "            yuv_mode,\n",
    "            device=device,\n",
    "            dct_size=dct_size,\n",
    "            is_half=False,\n",
    "            do_print=do_print,\n",
    "        ),\n",
    "        # IDCT(is_half=False, norm=norm),\n",
    "        RestoreMean(),\n",
    "        Upsample(mode=yuv_mode),\n",
    "        YcbcrToRgbMetadata(w_human),\n",
    "        Crop(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "image_enc, metadata = lvc_encoder([image_inp])[0]\n",
    "print(\"Done encoding\")\n",
    "image_out = lvc_decoder([(image_enc, metadata)])[0]\n",
    "\n",
    "mse = (image_out - image_inp).square().mean(dim=(1,2))\n",
    "psnr = 10 * torch.log10(torch.div(1.0**2, mse))\n",
    "\n",
    "print(\"MSE: \", mse)\n",
    "print(\"PSNR: \", psnr)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "fig.suptitle(\"Input image\")\n",
    "axs = axs.flatten()\n",
    "axs[0].imshow(image_inp[0], cmap=\"gray\")\n",
    "axs[0].set_title(\"Y\")\n",
    "axs[1].imshow(image_inp[1], cmap=\"gray\")\n",
    "axs[1].set_title(\"U\")\n",
    "axs[2].imshow(image_inp[2], cmap=\"gray\")\n",
    "axs[2].set_title(\"V\")\n",
    "axs[3].imshow(transforms.ToPILImage()(image_inp))\n",
    "axs[3].set_title(\"RGB\")\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "fig.suptitle(\"Restored image\")\n",
    "axs = axs.flatten()\n",
    "axs[0].imshow(image_out[0], cmap=\"gray\")\n",
    "axs[0].set_title(\"Y\")\n",
    "axs[1].imshow(image_out[1], cmap=\"gray\")\n",
    "axs[1].set_title(\"U\")\n",
    "axs[2].imshow(image_out[2], cmap=\"gray\")\n",
    "axs[2].set_title(\"V\")\n",
    "axs[3].imshow(transforms.ToPILImage()(image_out))\n",
    "axs[3].set_title(\"RGB\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from lvc import create_lvc\n",
    "from utils import set_device\n",
    "\n",
    "device = set_device()\n",
    "\n",
    "img_dir = Path(\"C:/kubouch/data/kodim/raw\")\n",
    "image_names = list(img_dir.glob(\"*.png\"))\n",
    "images = torch.stack([\n",
    "    # transforms.CenterCrop((288, 352))(\n",
    "    transforms.Resize((288, 672))(\n",
    "        transforms.ToTensor()(\n",
    "            Image.open(image_name).convert(mode=\"RGB\")\n",
    "        )\n",
    "    )\n",
    "    for image_name in image_names\n",
    "])\n",
    "\n",
    "dct_sizes = [None, (8, \"h\"), (8, \"v\"), (16, \"h\"), (16, \"v\")]\n",
    "packet_losses = [None, 0.0, 0.1, 0.25, 0.5, 0.75]\n",
    "num_chunks = [ 64, 256 ]\n",
    "estimators = ['zf', 'llse']\n",
    "csnrs = [ 0, 5, 10, 20, 30, 'inf']\n",
    "crs = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "for dct_size, packet_loss, nchunks, estimator, csnr, cr in product(dct_sizes, packet_losses, num_chunks, estimators, csnrs, crs):\n",
    "    lvc_params = {\n",
    "        \"packet_loss\": packet_loss,\n",
    "        \"seed\": 42,\n",
    "        \"mode\": 420,\n",
    "        \"cr\": cr,\n",
    "        \"csnr_db\": csnr,\n",
    "        \"estimator\": estimator,\n",
    "        \"nchunks\": nchunks\n",
    "    }\n",
    "\n",
    "    if dct_size is not None:\n",
    "        lvc_params[\"dct_w\"] = dct_size[0]\n",
    "        lvc_params[\"dct_h\"] = dct_size[0]\n",
    "        lvc_params[\"grouping\"] = dct_size[1]\n",
    "\n",
    "    lvc = create_lvc(lvc_params, device, half=False)\n",
    "    res = lvc(images)\n",
    "\n",
    "    psnrs = []\n",
    "    for inp, out in zip(images, res):\n",
    "        mse = (out - inp).square().mean()\n",
    "        psnrs.append(10 * torch.log10(1.0**2 / mse))\n",
    "\n",
    "    psnr = float(torch.tensor(psnrs).mean())\n",
    "\n",
    "    print(\"lvc_params: \", lvc_params, \", avg PSNR:\", psnr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('nn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2056f0fd95020c38eba01d39f4b8309efee9756a0a7bda45759d0dc0375c69c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
